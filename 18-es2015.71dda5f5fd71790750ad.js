(window.webpackJsonp=window.webpackJsonp||[]).push([[18],{wtaK:function(l,n,e){"use strict";e.r(n);var o=e("8Y7J");class t{constructor(){}ngOnInit(){}}class a{}var i=e("pMnS"),u=e("oBZk"),r=e("ZZ/e"),s=o.pb({encapsulation:0,styles:[[""]],data:{}});function d(l){return o.Hb(0,[(l()(),o.rb(0,0,null,null,10,"ion-header",[],null,null,null,u.K,u.m)),o.qb(1,49152,null,0,r.y,[o.h,o.k,o.x],null,null),(l()(),o.rb(2,0,null,0,8,"ion-toolbar",[],null,null,null,u.V,u.x)),o.qb(3,49152,null,0,r.yb,[o.h,o.k,o.x],null,null),(l()(),o.rb(4,0,null,0,3,"ion-buttons",[["slot","start"]],null,null,null,u.A,u.c)),o.qb(5,49152,null,0,r.i,[o.h,o.k,o.x],null,null),(l()(),o.rb(6,0,null,0,1,"ion-menu-button",[],null,null,null,u.P,u.s)),o.qb(7,49152,null,0,r.O,[o.h,o.k,o.x],null,null),(l()(),o.rb(8,0,null,0,2,"ion-title",[],null,null,null,u.U,u.w)),o.qb(9,49152,null,0,r.wb,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["Research"])),(l()(),o.rb(11,0,null,null,294,"ion-content",[],null,null,null,u.I,u.k)),o.qb(12,49152,null,0,r.r,[o.h,o.k,o.x],null,null),(l()(),o.rb(13,0,null,0,17,"ion-card",[],null,null,null,u.F,u.d)),o.qb(14,49152,null,0,r.j,[o.h,o.k,o.x],null,null),(l()(),o.rb(15,0,null,0,4,"ion-card-header",[],null,null,null,u.C,u.f)),o.qb(16,49152,null,0,r.l,[o.h,o.k,o.x],null,null),(l()(),o.rb(17,0,null,0,2,"ion-card-title",[["style","font-size:2em;"]],null,null,null,u.E,u.h)),o.qb(18,49152,null,0,r.n,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["Learning Locomotion using a Keyframe-based System"])),(l()(),o.rb(20,0,null,0,10,"ion-card-content",[],null,null,null,u.B,u.e)),o.qb(21,49152,null,0,r.k,[o.h,o.k,o.x],null,null),(l()(),o.rb(22,0,null,0,2,"ion-card-subtitle",[["style","font-size:1.5em;"]],null,null,null,u.D,u.g)),o.qb(23,49152,null,0,r.m,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["Ethan Wilson"])),(l()(),o.rb(25,0,null,0,2,"ion-card-subtitle",[["style","font-size:1.5em;"]],null,null,null,u.D,u.g)),o.qb(26,49152,null,0,r.m,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["Greg Turk"])),(l()(),o.rb(28,0,null,0,2,"ion-card-subtitle",[["style","font-size:1.5em;"]],null,null,null,u.D,u.g)),o.qb(29,49152,null,0,r.m,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["Yunbo Zhang"])),(l()(),o.rb(31,0,null,0,5,"ion-card",[["button","true"],["color","tertiary"],["download","draft.docx"],["href","assets/loco/draft.docx"]],null,null,null,u.F,u.d)),o.qb(32,49152,null,0,r.j,[o.h,o.k,o.x],{button:[0,"button"],color:[1,"color"],download:[2,"download"],href:[3,"href"]},null),(l()(),o.rb(33,0,null,0,3,"ion-card-content",[["style","text-align:center;"]],null,null,null,u.B,u.e)),o.qb(34,49152,null,0,r.k,[o.h,o.k,o.x],null,null),(l()(),o.rb(35,0,null,0,1,"h2",[],null,null,null,null,null)),(l()(),o.Gb(-1,null,["Download Paper"])),(l()(),o.rb(37,0,null,0,15,"ion-card",[],null,null,null,u.F,u.d)),o.qb(38,49152,null,0,r.j,[o.h,o.k,o.x],null,null),(l()(),o.rb(39,0,null,0,4,"ion-card-header",[],null,null,null,u.C,u.f)),o.qb(40,49152,null,0,r.l,[o.h,o.k,o.x],null,null),(l()(),o.rb(41,0,null,0,2,"ion-card-title",[],null,null,null,u.E,u.h)),o.qb(42,49152,null,0,r.n,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["Introduction"])),(l()(),o.rb(44,0,null,0,2,"ion-card-content",[],null,null,null,u.B,u.e)),o.qb(45,49152,null,0,r.k,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["\nAnimated motion of a digital character / model is derived from a few different methods which depend on the simulation environment. Traditional animation, applied in video games, animated film, etc., keeps a record of keyframes, or values for the rotation of joints within a model's underlying skeleton. These keyframes correspond to different points in time, and the program interpolates between them to generate the animation. These keyframes are typically either animated by hand or obtained through motion capture technology. "])),(l()(),o.rb(47,0,null,0,2,"ion-card-content",[],null,null,null,u.B,u.e)),o.qb(48,49152,null,0,r.k,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["\nAnimations that must conform to the laws of physics, i.e. existing within physics simulations, must be animated in a different manner. Real humans / creatures perform an infinite amount of subconscious motions to preserve balance and save energy, but it would take an exorbitant amount of time for a human animator to replicate those balance changes using keyframes in a physical simulation. Without those corrections, realistic-looking animation loops might lose their stability over time, resulting in the agent falling over, and successfully human-animated motion would likely look robotic or simulated. "])),(l()(),o.rb(50,0,null,0,2,"ion-card-content",[],null,null,null,u.B,u.e)),o.qb(51,49152,null,0,r.k,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["\nMy goal was to create a physics-based animation system that could import custom models and generate stable walk cycles [i.e. completing multiple cycles without falling over, yet still moving in the forward direction] within an affordable amount of time. "])),(l()(),o.rb(53,0,null,0,7,"ion-card",[["color","secondary"],["style","margin:auto;width:60%;"]],null,null,null,u.F,u.d)),o.qb(54,49152,null,0,r.j,[o.h,o.k,o.x],{color:[0,"color"]},null),(l()(),o.rb(55,0,null,0,5,"ion-card-content",[],null,null,null,u.B,u.e)),o.qb(56,49152,null,0,r.k,[o.h,o.k,o.x],null,null),(l()(),o.rb(57,0,null,0,3,"ion-card",[["color","dark"],["style","padding:10px"]],null,null,null,u.F,u.d)),o.qb(58,49152,null,0,r.j,[o.h,o.k,o.x],{color:[0,"color"]},null),(l()(),o.rb(59,0,null,0,1,"video",[["controls","controls"],["style","display:block;width:100%;height:auto;margin-left:auto;margin-right:auto;"]],null,null,null,null,null)),(l()(),o.rb(60,0,null,null,0,"source",[["src","assets/loco/video/quad_good_walk.mp4"],["type","video/mp4"]],null,null,null,null,null)),(l()(),o.rb(61,0,null,0,12,"ion-card",[],null,null,null,u.F,u.d)),o.qb(62,49152,null,0,r.j,[o.h,o.k,o.x],null,null),(l()(),o.rb(63,0,null,0,4,"ion-card-header",[],null,null,null,u.C,u.f)),o.qb(64,49152,null,0,r.l,[o.h,o.k,o.x],null,null),(l()(),o.rb(65,0,null,0,2,"ion-card-title",[],null,null,null,u.E,u.h)),o.qb(66,49152,null,0,r.n,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["Related Work"])),(l()(),o.rb(68,0,null,0,2,"ion-card-content",[],null,null,null,u.B,u.e)),o.qb(69,49152,null,0,r.k,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,['\nTraditionally, the solution for animating with respect to physical constraints has been to employ some heuristic optimization algorithm. Heuristic algorithms do not search for a single perfect solution; instead they approximate a solution that is "good enough" and can be found in a reasonable amount of time. These algorithms are especially effective in locomotion because of the large problem space (there are infinite variations of acceptable forms of locomotion). Evolutionary algorithms work particularly well as they tend to avoid local maxima and can indefinitely continue searching for a more efficient solution. For example, Kodjabachian used an evolutionary approach to build a neural network controller for simulated two-dimensional insects. These insects were able to learn locomotion and perform higher level behaviors, such as obstacle avoidance and an odor-gradient food detection system[1]. '])),(l()(),o.rb(71,0,null,0,2,"ion-card-content",[],null,null,null,u.B,u.e)),o.qb(72,49152,null,0,r.k,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["\nRecent improvements in computational technology have opened the gateway to apply more computationally expensive algorithms. Reinforcement learning (RL), a subset of machine learning that balances an agent's environmental exploration vs. exploitation, has become an especially popular method. There are various existing implementations of RL locomotion training, and some have extended functionality for various scenarios. An example is Simbicon, a three-dimensional biped locomotion controller that incorporated the ability to react to varied terrain and outside forces[2]. However, these solutions remain too computationally expensive to perform without a dedicated setup. While a research lab might be able to afford a week of training on a dedicated multi-GPU system, I am restricted to using a mid-range laptop. "])),(l()(),o.rb(74,0,null,0,7,"ion-card",[["color","secondary"],["style","margin:auto;width:60%;"]],null,null,null,u.F,u.d)),o.qb(75,49152,null,0,r.j,[o.h,o.k,o.x],{color:[0,"color"]},null),(l()(),o.rb(76,0,null,0,5,"ion-card-content",[],null,null,null,u.B,u.e)),o.qb(77,49152,null,0,r.k,[o.h,o.k,o.x],null,null),(l()(),o.rb(78,0,null,0,3,"ion-card",[["color","dark"],["style","padding:10px"]],null,null,null,u.F,u.d)),o.qb(79,49152,null,0,r.j,[o.h,o.k,o.x],{color:[0,"color"]},null),(l()(),o.rb(80,0,null,0,1,"video",[["controls","controls"],["style","display:block;width:100%;height:auto;margin-left:auto;margin-right:auto;"]],null,null,null,null,null)),(l()(),o.rb(81,0,null,null,0,"source",[["src","assets/loco/video/crab_run.mp4"],["type","video/mp4"]],null,null,null,null,null)),(l()(),o.rb(82,0,null,0,9,"ion-card",[],null,null,null,u.F,u.d)),o.qb(83,49152,null,0,r.j,[o.h,o.k,o.x],null,null),(l()(),o.rb(84,0,null,0,4,"ion-card-header",[],null,null,null,u.C,u.f)),o.qb(85,49152,null,0,r.l,[o.h,o.k,o.x],null,null),(l()(),o.rb(86,0,null,0,2,"ion-card-title",[],null,null,null,u.E,u.h)),o.qb(87,49152,null,0,r.n,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["My Approach"])),(l()(),o.rb(89,0,null,0,2,"ion-card-content",[],null,null,null,u.B,u.e)),o.qb(90,49152,null,0,r.k,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["\nMy implementation used a Genetic Algorithm (GA), an evolutionary algorithm in which various DNA compete within a population that evolves over time. In order to save computation time and limit the problem's search space, I opted to model my DNA after the keyframe system present in traditional animation. Thus, my solution is prone to the problems animators face (discussed in the introduction), but it is able to achieve significantly more precise values than any human animator could. "])),(l()(),o.rb(92,0,null,0,7,"ion-card",[["color","secondary"],["style","margin:auto;width:60%;"]],null,null,null,u.F,u.d)),o.qb(93,49152,null,0,r.j,[o.h,o.k,o.x],{color:[0,"color"]},null),(l()(),o.rb(94,0,null,0,5,"ion-card-content",[],null,null,null,u.B,u.e)),o.qb(95,49152,null,0,r.k,[o.h,o.k,o.x],null,null),(l()(),o.rb(96,0,null,0,3,"ion-card",[["color","dark"],["style","padding:10px"]],null,null,null,u.F,u.d)),o.qb(97,49152,null,0,r.j,[o.h,o.k,o.x],{color:[0,"color"]},null),(l()(),o.rb(98,0,null,0,1,"video",[["controls","controls"],["style","display:block;width:100%;height:auto;margin-left:auto;margin-right:auto;"]],null,null,null,null,null)),(l()(),o.rb(99,0,null,null,0,"source",[["src","assets/loco/video/tall_walk.mp4"],["type","video/mp4"]],null,null,null,null,null)),(l()(),o.rb(100,0,null,0,21,"ion-card",[],null,null,null,u.F,u.d)),o.qb(101,49152,null,0,r.j,[o.h,o.k,o.x],null,null),(l()(),o.rb(102,0,null,0,4,"ion-card-header",[],null,null,null,u.C,u.f)),o.qb(103,49152,null,0,r.l,[o.h,o.k,o.x],null,null),(l()(),o.rb(104,0,null,0,2,"ion-card-title",[],null,null,null,u.E,u.h)),o.qb(105,49152,null,0,r.n,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["Skel Controller within DART"])),(l()(),o.rb(107,0,null,0,2,"ion-card-content",[],null,null,null,u.B,u.e)),o.qb(108,49152,null,0,r.k,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["\nThe physics simulation I chose to use was the Dynamic Animation and Robotics Toolkit (DART). DART is an open-source library that was written at the Georgia Institute of Technology collaboratively by the Graphics Lab and Humanoid Robotics Lab[3]. I chose DART both because it is an ideal environment for simulating rigid body systems and because of my advisors' experience with the program. "])),(l()(),o.rb(110,0,null,0,2,"ion-card-content",[],null,null,null,u.B,u.e)),o.qb(111,49152,null,0,r.k,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["\nDART's functionality includes a customizable controller for every rigid body entity within the simulation. This controller can be used to dynamically apply torque to the joints of the rigid body during the simulation's runtime. The controller I implemented was an extension of the Stable Proportional-Derivative (SPD) controller[4]. In the context of a rigidbody system, a SPD controller provides stable tracking to a target pose. This is achieved by applying a control force to the rigid body's joints, computed using the joint's current kinematics, the target position, and the simulation's timestep. A proportional gain (tracking strength) and derivative gain (damping strength) are included in the equation used and can be changed to tweak the tracking intensity. SPD controllers differ from traditional Proportional-Derivative (PD) controllers in their calculation; SPD use a computed estimate of the simulation's next time-step rather than the current time-step. This method ensures stability when undergoing large motions or high time steps, whereas the traditional PD controller may break down. "])),(l()(),o.rb(113,0,null,0,2,"ion-card-content",[],null,null,null,u.B,u.e)),o.qb(114,49152,null,0,r.k,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["\nMy controller utilizes the SPD controller's computations for all torque calculations. At the initialization phase of the simulation, my controller is fed a list of tracking poses. Then, when applicable, these poses are mirrored and/or interpolated to generate a large cycle of poses for the controller to use. "])),(l()(),o.rb(116,0,null,0,2,"ion-card-content",[],null,null,null,u.B,u.e)),o.qb(117,49152,null,0,r.k,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["\nTo mirror a pose, specific values within the pose (referred to as degrees of freedom, explained in-depth in a later section) that map from left to right are transferred to the opposite side, and vice versa. The code to mirror depends on the model at hand. Interpolation can be applied generally to any model. To interpolate, two adjacent poses from within the loop are chosen. Multiple intermediate poses are generated by linearly interpolating between the two chosen poses. These generated poses are then added to a new list which ends up being much larger. This process is repeated between each adjacent pair of poses, with the interpolated poses being added to the same new list, which finally replaces the initial list of poses. "])),(l()(),o.rb(119,0,null,0,2,"ion-card-content",[],null,null,null,u.B,u.e)),o.qb(120,49152,null,0,r.k,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["\nAt runtime, the controller tracks to a pose and constantly computes an error value between the model's current position and the pose being tracked. Once this error drops beneath a specific value, the target pose shifts to the next pose in the list. Using error to determine when to track a new pose differs from animation's traditional keyframe approach, where the tracking of keyframes are based completely on time. My approach generated smoother motions than a linear time-based system would; additionally, this system discouraged unexpected behaviors by adding physical constraints to the rigidbody. If a model was unable to reach its next pose (from falling over and being blocked by the ground, or any other reason), it would get stuck, whereas a strictly time-based keyframe system's model would ignore the fact that it was stuck and continue attempting to reach poses, resulting in unnatural, spastic motion. "])),(l()(),o.rb(122,0,null,0,7,"ion-card",[["color","secondary"],["style","margin:auto;width:60%;"]],null,null,null,u.F,u.d)),o.qb(123,49152,null,0,r.j,[o.h,o.k,o.x],{color:[0,"color"]},null),(l()(),o.rb(124,0,null,0,5,"ion-card-content",[],null,null,null,u.B,u.e)),o.qb(125,49152,null,0,r.k,[o.h,o.k,o.x],null,null),(l()(),o.rb(126,0,null,0,3,"ion-card",[["color","dark"],["style","padding:10px"]],null,null,null,u.F,u.d)),o.qb(127,49152,null,0,r.j,[o.h,o.k,o.x],{color:[0,"color"]},null),(l()(),o.rb(128,0,null,0,1,"video",[["controls","controls"],["style","display:block;width:100%;height:auto;margin-left:auto;margin-right:auto;"]],null,null,null,null,null)),(l()(),o.rb(129,0,null,null,0,"source",[["src","assets/loco/video/quad_mirror_pose.mp4"],["type","video/mp4"]],null,null,null,null,null)),(l()(),o.rb(130,0,null,0,9,"ion-card",[],null,null,null,u.F,u.d)),o.qb(131,49152,null,0,r.j,[o.h,o.k,o.x],null,null),(l()(),o.rb(132,0,null,0,4,"ion-card-header",[],null,null,null,u.C,u.f)),o.qb(133,49152,null,0,r.l,[o.h,o.k,o.x],null,null),(l()(),o.rb(134,0,null,0,2,"ion-card-title",[],null,null,null,u.E,u.h)),o.qb(135,49152,null,0,r.n,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["Genetic Algorithm"])),(l()(),o.rb(137,0,null,0,2,"ion-card-content",[],null,null,null,u.B,u.e)),o.qb(138,49152,null,0,r.k,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["\nA genetic algorithm (GA) is a framework for solving optimization problems which is based upon the process of natural selection found in biological evolution. Different solutions to the problem, referred to as genomes, are initially randomly generated by the algorithm. These genomes are stored in a list of fixed size known as the population. The algorithm progresses by alternating between evolutionary and evaluation stages. At each evaluation stage, every genome in the population is tested against a fitness function and given a score which corresponds to how effectively they have solved the problem. The evolutionary stage typically involves a combination of crossover and mutation. Crossover is a process in which two genomes, now known as the parents, are selected from the population and their information is combined to produce some number of children. Mutation takes in a single genome sequence and slightly changes some of its values, creating a slightly different solution to the problem. Crossover and mutations are performed on the population in an effort to produce better solutions that can be used in later generations. At the end of each evolutionary stage, the population, which may contain extra DNA from crossover, must be culled back to its original size. "])),(l()(),o.rb(140,0,null,0,7,"ion-card",[["color","secondary"],["style","margin:auto;width:60%;"]],null,null,null,u.F,u.d)),o.qb(141,49152,null,0,r.j,[o.h,o.k,o.x],{color:[0,"color"]},null),(l()(),o.rb(142,0,null,0,5,"ion-card-content",[],null,null,null,u.B,u.e)),o.qb(143,49152,null,0,r.k,[o.h,o.k,o.x],null,null),(l()(),o.rb(144,0,null,0,3,"ion-card",[["color","dark"],["style","padding:10px"]],null,null,null,u.F,u.d)),o.qb(145,49152,null,0,r.j,[o.h,o.k,o.x],{color:[0,"color"]},null),(l()(),o.rb(146,0,null,0,1,"video",[["controls","controls"],["style","display:block;width:100%;height:auto;margin-left:auto;margin-right:auto;"]],null,null,null,null,null)),(l()(),o.rb(147,0,null,null,0,"source",[["src","assets/loco/video/crab_flipped.mp4"],["type","video/mp4"]],null,null,null,null,null)),(l()(),o.rb(148,0,null,0,35,"ion-card",[],null,null,null,u.F,u.d)),o.qb(149,49152,null,0,r.j,[o.h,o.k,o.x],null,null),(l()(),o.rb(150,0,null,0,4,"ion-card-header",[],null,null,null,u.C,u.f)),o.qb(151,49152,null,0,r.l,[o.h,o.k,o.x],null,null),(l()(),o.rb(152,0,null,0,2,"ion-card-title",[],null,null,null,u.E,u.h)),o.qb(153,49152,null,0,r.n,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["Data Storage"])),(l()(),o.rb(155,0,null,0,2,"ion-card-content",[],null,null,null,u.B,u.e)),o.qb(156,49152,null,0,r.k,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["\nI chose to represent my DNA as a list of target poses for the controller within DART to use. Every pose was a list of values, and each value corresponded to the rotation value of one degrees of freedom (DOF) within the model. "])),(l()(),o.rb(158,0,null,0,2,"ion-card-content",[],null,null,null,u.B,u.e)),o.qb(159,49152,null,0,r.k,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["\nA model is composed of various body sections, which are connected by joints. There are multiple joint classifications to choose from, with the more complicated joint types having more DOFs. A DOF is a single value that corresponds to one axis of rotation in the world (the axis can be of any orientation, however). The types of joints are as follows: "])),(l()(),o.rb(161,0,null,0,16,"ion-list",[["color","tertiary"],["lines","none"],["style","margin:auto;width:80%;"]],null,null,null,u.O,u.q)),o.qb(162,49152,null,0,r.L,[o.h,o.k,o.x],{lines:[0,"lines"]},null),(l()(),o.rb(163,0,null,0,2,"ion-item",[],null,null,null,u.M,u.o)),o.qb(164,49152,null,0,r.E,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["\n1. Revolute joints contain one DOF. An example would be a human's elbow, which can only rotate along the bicep's orientation. Notice, however, that as the shoulder moves the elbow's global rotation also changes, so the revolute joint's constraint is only local to the body part it is placed on. "])),(l()(),o.rb(166,0,null,0,2,"ion-item",[],null,null,null,u.M,u.o)),o.qb(167,49152,null,0,r.E,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["\n2. Universal joints contain two DOFs. An example is the human knee, which can rotate along the thigh's orientation or rotate slightly along the calf's axis. It can not rotate all the way around the thigh due to having two axes of rotation in a 3D space. "])),(l()(),o.rb(169,0,null,0,2,"ion-item",[],null,null,null,u.M,u.o)),o.qb(170,49152,null,0,r.E,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["\n3. Euler joints contain three DOFs, and can rotate along all axes. An example is the shoulder. Notice that the shoulder still has value constraints. It can rotate along every axis, but the extent of rotation is limited by the person's flexibility. "])),(l()(),o.rb(172,0,null,0,2,"ion-item",[],null,null,null,u.M,u.o)),o.qb(173,49152,null,0,r.E,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["\n4. Free joints connect two separate objects and contain three DOFs for rotation and three DOFs for position. These joints can not be directly manipulated and exist solely to inform the simulation. "])),(l()(),o.rb(175,0,null,0,2,"ion-item",[],null,null,null,u.M,u.o)),o.qb(176,49152,null,0,r.E,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["\n5. Weld joints have zero DOFs and rigidly connect two body parts. These help to create more complex geometry by combining primitive shapes. "])),(l()(),o.rb(178,0,null,0,2,"ion-card-content",[],null,null,null,u.B,u.e)),o.qb(179,49152,null,0,r.k,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["\nLimiting the number of DOFs on a model would decrease computation time, so models were created creatively to have the simplest combination of joints while still being able to achieve motion similar to the creatures they were modeled after. In addition, I limited the values of these DOFs within the DNA to have a roughly 90 degree range. This restriction acted similarly to a human shoulder in that without constraints, a shoulder would be able to clip into its attached body. This helped to both keep movement natural and to decrease the problem's search space significantly. "])),(l()(),o.rb(181,0,null,0,2,"ion-card-content",[],null,null,null,u.B,u.e)),o.qb(182,49152,null,0,r.k,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["\nTo save additional computation time, for symmetrical models I implemented a mirror system. Each piece of DNA would only contain info for half of a walk cycle, which would then be mirrored over at the beginning of the evaluation phase. This halved the amount of data in the GA, which exponentially decreased search time. "])),(l()(),o.rb(184,0,null,0,7,"ion-card",[["color","secondary"],["style","margin:auto;width:60%;"]],null,null,null,u.F,u.d)),o.qb(185,49152,null,0,r.j,[o.h,o.k,o.x],{color:[0,"color"]},null),(l()(),o.rb(186,0,null,0,5,"ion-card-content",[],null,null,null,u.B,u.e)),o.qb(187,49152,null,0,r.k,[o.h,o.k,o.x],null,null),(l()(),o.rb(188,0,null,0,3,"ion-card",[["color","dark"],["style","padding:10px"]],null,null,null,u.F,u.d)),o.qb(189,49152,null,0,r.j,[o.h,o.k,o.x],{color:[0,"color"]},null),(l()(),o.rb(190,0,null,0,1,"video",[["controls","controls"],["style","display:block;width:100%;height:auto;margin-left:auto;margin-right:auto;"]],null,null,null,null,null)),(l()(),o.rb(191,0,null,null,0,"source",[["src","assets/loco/video/alien_crawl.mp4"],["type","video/mp4"]],null,null,null,null,null)),(l()(),o.rb(192,0,null,0,15,"ion-card",[],null,null,null,u.F,u.d)),o.qb(193,49152,null,0,r.j,[o.h,o.k,o.x],null,null),(l()(),o.rb(194,0,null,0,4,"ion-card-header",[],null,null,null,u.C,u.f)),o.qb(195,49152,null,0,r.l,[o.h,o.k,o.x],null,null),(l()(),o.rb(196,0,null,0,2,"ion-card-title",[],null,null,null,u.E,u.h)),o.qb(197,49152,null,0,r.n,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["Fitness Evaluation"])),(l()(),o.rb(199,0,null,0,2,"ion-card-content",[],null,null,null,u.B,u.e)),o.qb(200,49152,null,0,r.k,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["\nEvery evaluation stage of the GA, all DNA need to be run against a fitness function so that they can be ranked as effective solutions to the problem at hand. My fitness functions varied for different models, but were all based around running a DART simulation for a specific amount of time and returning a value based on how far forward the model travelled. "])),(l()(),o.rb(202,0,null,0,2,"ion-card-content",[],null,null,null,u.B,u.e)),o.qb(203,49152,null,0,r.k,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["\nSome models needed more complicated fitness functions to accommodate unexpected behaviors that arose. The agent's only goal is to get the highest score, so without extra bounds to restrict movement, the best solution the GA founds could be an unnatural looking exploit. For example, when given a simple \"go forward\" fitness function, my quadruped model discovered that it could travel fastest by somersaulting instead of walking. To fix this, I added the constraint in which the agent's average foot-to-ground distance influenced the highest score. This heavily penalized the somersault behavior without discouraging a regular walk cycle. "])),(l()(),o.rb(205,0,null,0,2,"ion-card-content",[],null,null,null,u.B,u.e)),o.qb(206,49152,null,0,r.k,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["\nThe most common exploit agents found were that they could use their poses to perform one large jump instantly, and the distance they traveled would be further than an actual walk cycle. The agent would get stuck at this local maxima for many generations. I hypothesize that given a large enough simulation runtime and enough training generations this behavior would self-correct, but I did not have the patience to run any tests long enough to see this happen (three days were not long enough). More specific results will be explained in a later section. "])),(l()(),o.rb(208,0,null,0,7,"ion-card",[["color","secondary"],["style","margin:auto;width:60%;"]],null,null,null,u.F,u.d)),o.qb(209,49152,null,0,r.j,[o.h,o.k,o.x],{color:[0,"color"]},null),(l()(),o.rb(210,0,null,0,5,"ion-card-content",[],null,null,null,u.B,u.e)),o.qb(211,49152,null,0,r.k,[o.h,o.k,o.x],null,null),(l()(),o.rb(212,0,null,0,3,"ion-card",[["color","dark"],["style","padding:10px"]],null,null,null,u.F,u.d)),o.qb(213,49152,null,0,r.j,[o.h,o.k,o.x],{color:[0,"color"]},null),(l()(),o.rb(214,0,null,0,1,"video",[["controls","controls"],["style","display:block;width:100%;height:auto;margin-left:auto;margin-right:auto;"]],null,null,null,null,null)),(l()(),o.rb(215,0,null,null,0,"source",[["src","assets/loco/video/quad_slow_walk.mp4"],["type","video/mp4"]],null,null,null,null,null)),(l()(),o.rb(216,0,null,0,15,"ion-card",[],null,null,null,u.F,u.d)),o.qb(217,49152,null,0,r.j,[o.h,o.k,o.x],null,null),(l()(),o.rb(218,0,null,0,4,"ion-card-header",[],null,null,null,u.C,u.f)),o.qb(219,49152,null,0,r.l,[o.h,o.k,o.x],null,null),(l()(),o.rb(220,0,null,0,2,"ion-card-title",[],null,null,null,u.E,u.h)),o.qb(221,49152,null,0,r.n,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["Evolution"])),(l()(),o.rb(223,0,null,0,2,"ion-card-content",[],null,null,null,u.B,u.e)),o.qb(224,49152,null,0,r.k,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["\nMy methods for mutation and crossover were customized to accomodate my specific locomotion problem. My mutation function would take a DNA sequence, choose a random pose from within the list, and randomly select two DOFs to change. These DOFs were reassigned random values within the 90 degree target range. My mutation function's goal was to discover slight tweaks that could finely tweak the balance of a model's walk cycle. My method for crossover focused only on the poses, ignoring the specific values contained in each pose. Two parent DNA were chosen randomly from the population and their pose combinations were permuted to produce unique children. The parents and children were all returned into the population. "])),(l()(),o.rb(226,0,null,0,2,"ion-card-content",[],null,null,null,u.B,u.e)),o.qb(227,49152,null,0,r.k,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["\nThe evolution stage of my algorithm would repeatedly perform crossovers between random parents. This grew the overall population, so the repeated crossovers terminated once the new population reached a certain size. At that point, the entire [large] population would be evaluated and sorted based on the genomes' fitness evaluation. Then the population would be culled back to its original size, with checks put in place to prevent identical DNA copies from surviving. By only performing crossovers, the population eventually would normalize and mix to the point of little genetic variation. "])),(l()(),o.rb(229,0,null,0,2,"ion-card-content",[],null,null,null,u.B,u.e)),o.qb(230,49152,null,0,r.k,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["\nThe algorithm kept track of a population's average fitness as well as the highest individual and underwent a special period of \"forced evolution\" if no significant growth was made over multiple generations. This forced evolution period consisted of rapid mutations and the generation of entirely random new DNA. If a generated DNA was deemed fit, it would be inserted into the population. Once the population had been sufficiently revitalized, the algorithm would continue and the regular crossover evolution would resume. The forced evolution stage's purpose was to work around the local maxima and broaden the algorithm's search space to find better solutions. As the found solution became better, the forced evolutionary period would take longer and would (typically) result in less extreme jumps in progress. This gave me insight for when to terminate the program, as progress would eventually slow enough to not be worth the runtime. "])),(l()(),o.rb(232,0,null,0,7,"ion-card",[["color","secondary"],["style","margin:auto;width:60%;"]],null,null,null,u.F,u.d)),o.qb(233,49152,null,0,r.j,[o.h,o.k,o.x],{color:[0,"color"]},null),(l()(),o.rb(234,0,null,0,5,"ion-card-content",[],null,null,null,u.B,u.e)),o.qb(235,49152,null,0,r.k,[o.h,o.k,o.x],null,null),(l()(),o.rb(236,0,null,0,3,"ion-card",[["color","dark"],["style","padding:10px"]],null,null,null,u.F,u.d)),o.qb(237,49152,null,0,r.j,[o.h,o.k,o.x],{color:[0,"color"]},null),(l()(),o.rb(238,0,null,0,1,"video",[["controls","controls"],["style","display:block;width:100%;height:auto;margin-left:auto;margin-right:auto;"]],null,null,null,null,null)),(l()(),o.rb(239,0,null,null,0,"source",[["src","assets/loco/video/duck_fail.mp4"],["type","video/mp4"]],null,null,null,null,null)),(l()(),o.rb(240,0,null,0,18,"ion-card",[],null,null,null,u.F,u.d)),o.qb(241,49152,null,0,r.j,[o.h,o.k,o.x],null,null),(l()(),o.rb(242,0,null,0,4,"ion-card-header",[],null,null,null,u.C,u.f)),o.qb(243,49152,null,0,r.l,[o.h,o.k,o.x],null,null),(l()(),o.rb(244,0,null,0,2,"ion-card-title",[],null,null,null,u.E,u.h)),o.qb(245,49152,null,0,r.n,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["Results"])),(l()(),o.rb(247,0,null,0,2,"ion-card-content",[],null,null,null,u.B,u.e)),o.qb(248,49152,null,0,r.k,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["\nMy goal to create stable physics-based walk cycles was achieved. Despite having limited hardware, my learning algorithm provided consistent, quick results. The algorithm would converge upon a solution within 8 hours of testing, with simpler models taking less time. Tests that ran longer had only marginal efficiency gains. "])),(l()(),o.rb(250,0,null,0,2,"ion-card-content",[],null,null,null,u.B,u.e)),o.qb(251,49152,null,0,r.k,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["\nA secondary goal was for the motion to look realistic and mimic that of real creatures' walk cycles. While none of my motion looked robotic, it also did not look completely organic. The walk cycles tended to look sluggish. Smaller motions that do not change the model's center of gravity are typically more stable, so the solutions the algorithm produced tended not to have large movements. Another reason is the manually set tracking and damping strength. I set these values relatively low, which resulted in weaker creatures. I did this mainly because weaker creatures have less unexpected behaviors; therefore, their fitness functions' constraints are easier to write and quicker to test. "])),(l()(),o.rb(253,0,null,0,2,"ion-card-content",[],null,null,null,u.B,u.e)),o.qb(254,49152,null,0,r.k,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["\nSome of the unexpected behaviors were insightful and quite entertaining to look at. For example, the quadruped that opted to somersault shows what organic motion might have been like if there was no concept of tiredness. Some models were designed with specific motions in mind, but performed entirely differently. I designed a creature with two legs and a large tail, thinking it would propel itself forward with the tail; instead, it decided to lift the tail in the air and crawl. "])),(l()(),o.rb(256,0,null,0,2,"ion-card-content",[],null,null,null,u.B,u.e)),o.qb(257,49152,null,0,r.k,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["\nI discovered that I could add early termination to the fitness functions of some models to speed up the training period. If I could identify a behavior that a walk cycle would never have, such as the model being upside down or high up in the air, a conditional in my code would give that DNA a very low score and terminate the simulation early. This shortcut improved early performance greatly, when DNA were prone to random motion, and become less impactful further on as DNA converged to a stable solution. "])),(l()(),o.rb(259,0,null,0,7,"ion-card",[["color","secondary"],["style","margin:auto;width:60%;"]],null,null,null,u.F,u.d)),o.qb(260,49152,null,0,r.j,[o.h,o.k,o.x],{color:[0,"color"]},null),(l()(),o.rb(261,0,null,0,5,"ion-card-content",[],null,null,null,u.B,u.e)),o.qb(262,49152,null,0,r.k,[o.h,o.k,o.x],null,null),(l()(),o.rb(263,0,null,0,3,"ion-card",[["color","dark"],["style","padding:10px"]],null,null,null,u.F,u.d)),o.qb(264,49152,null,0,r.j,[o.h,o.k,o.x],{color:[0,"color"]},null),(l()(),o.rb(265,0,null,0,1,"video",[["controls","controls"],["style","display:block;width:100%;height:auto;margin-left:auto;margin-right:auto;"]],null,null,null,null,null)),(l()(),o.rb(266,0,null,null,0,"source",[["src","assets/loco/video/alien_lifted_tail.mp4"],["type","video/mp4"]],null,null,null,null,null)),(l()(),o.rb(267,0,null,0,9,"ion-card",[],null,null,null,u.F,u.d)),o.qb(268,49152,null,0,r.j,[o.h,o.k,o.x],null,null),(l()(),o.rb(269,0,null,0,4,"ion-card-header",[],null,null,null,u.C,u.f)),o.qb(270,49152,null,0,r.l,[o.h,o.k,o.x],null,null),(l()(),o.rb(271,0,null,0,2,"ion-card-title",[],null,null,null,u.E,u.h)),o.qb(272,49152,null,0,r.n,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["Future Implications"])),(l()(),o.rb(274,0,null,0,2,"ion-card-content",[],null,null,null,u.B,u.e)),o.qb(275,49152,null,0,r.k,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["\nThis method of locomotion learning is structured very similarly to the keyframe system present in traditional animation. Because of this similarity, traditional animation skeletons could be ported into the learning algorithm. If this method were refined and tweaked to search for a local maxima based on the ported animation, the program would be able to finely tweak hand-made animations to become stable and physically accurate. Obviously, hand-made animation is made to look realistic rather than be realistic, so there is no guarantee that a physically accurate animation would look better. If nothing else, a video game or film that employed this technique would have some added novelty. As an alternative, animators could simply use the program as a training tool to practice their realism. "])),(l()(),o.rb(277,0,null,0,7,"ion-card",[["color","secondary"],["style","margin:auto;width:60%;"]],null,null,null,u.F,u.d)),o.qb(278,49152,null,0,r.j,[o.h,o.k,o.x],{color:[0,"color"]},null),(l()(),o.rb(279,0,null,0,5,"ion-card-content",[],null,null,null,u.B,u.e)),o.qb(280,49152,null,0,r.k,[o.h,o.k,o.x],null,null),(l()(),o.rb(281,0,null,0,3,"ion-card",[["color","dark"],["style","padding:10px"]],null,null,null,u.F,u.d)),o.qb(282,49152,null,0,r.j,[o.h,o.k,o.x],{color:[0,"color"]},null),(l()(),o.rb(283,0,null,0,1,"video",[["controls","controls"],["style","display:block;width:100%;height:auto;margin-left:auto;margin-right:auto;"]],null,null,null,null,null)),(l()(),o.rb(284,0,null,null,0,"source",[["src","assets/loco/video/quad_butt_scoot.mp4"],["type","video/mp4"]],null,null,null,null,null)),(l()(),o.rb(285,0,null,0,20,"ion-card",[],null,null,null,u.F,u.d)),o.qb(286,49152,null,0,r.j,[o.h,o.k,o.x],null,null),(l()(),o.rb(287,0,null,0,4,"ion-card-header",[],null,null,null,u.C,u.f)),o.qb(288,49152,null,0,r.l,[o.h,o.k,o.x],null,null),(l()(),o.rb(289,0,null,0,2,"ion-card-title",[],null,null,null,u.E,u.h)),o.qb(290,49152,null,0,r.n,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,["Citations"])),(l()(),o.rb(292,0,null,0,13,"ion-list",[["color","tertiary"],["lines","none"],["style","margin:auto;width:80%;"]],null,null,null,u.O,u.q)),o.qb(293,49152,null,0,r.L,[o.h,o.k,o.x],{lines:[0,"lines"]},null),(l()(),o.rb(294,0,null,0,2,"ion-item",[["style","padding:5px;"]],null,null,null,u.M,u.o)),o.qb(295,49152,null,0,r.E,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,['\n[1] Kodjabachian, J., and J.-A. Meyer. 1998. "Evolution and Development of Neural Controllers for Locomotion, Gradient-Following, and Obstacle-Avoidance in Artificial Insects." IEEE Transactions on Neural Networks 9 (5): 796-812. doi:10.1109/72.712153. '])),(l()(),o.rb(297,0,null,0,2,"ion-item",[["style","padding:5px;"]],null,null,null,u.M,u.o)),o.qb(298,49152,null,0,r.E,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,['\n[2] Yin, KangKang, Kevin Loken, and Michiel van de Panne. "SIMBICON: Simple Biped Locomotion Control." Simbicon Project Webpage. University of British Columbia. https://www.cs.ubc.ca/~van/papers/Simbicon.htm. '])),(l()(),o.rb(300,0,null,0,2,"ion-item",[["style","padding:5px;"]],null,null,null,u.M,u.o)),o.qb(301,49152,null,0,r.E,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,['\n[3] "Dynamic Animation and Robotics Toolkit." DART, Georgia Tech and Carnegie Mellon University, 6 June 2019, https://dartsim.github.io. '])),(l()(),o.rb(303,0,null,0,2,"ion-item",[["style","padding:5px;"]],null,null,null,u.M,u.o)),o.qb(304,49152,null,0,r.E,[o.h,o.k,o.x],null,null),(l()(),o.Gb(-1,0,['\n[4] Tan, Jie, Karen Liu, and Greg Turk. "Stable Proportional-Derivative Controllers." http://www.jie-tan.net/project/spd.html. ']))],function(l,n){l(n,32,0,"true","tertiary","draft.docx","assets/loco/draft.docx"),l(n,54,0,"secondary"),l(n,58,0,"dark"),l(n,75,0,"secondary"),l(n,79,0,"dark"),l(n,93,0,"secondary"),l(n,97,0,"dark"),l(n,123,0,"secondary"),l(n,127,0,"dark"),l(n,141,0,"secondary"),l(n,145,0,"dark"),l(n,162,0,"none"),l(n,185,0,"secondary"),l(n,189,0,"dark"),l(n,209,0,"secondary"),l(n,213,0,"dark"),l(n,233,0,"secondary"),l(n,237,0,"dark"),l(n,260,0,"secondary"),l(n,264,0,"dark"),l(n,278,0,"secondary"),l(n,282,0,"dark"),l(n,293,0,"none")},null)}function c(l){return o.Hb(0,[(l()(),o.rb(0,0,null,null,1,"app-locomotion",[],null,null,null,d,s)),o.qb(1,114688,null,0,t,[],null,null)],function(l,n){l(n,1,0)},null)}var h=o.nb("app-locomotion",t,c,{},{},[]),b=e("SVse"),m=e("s7LF"),p=e("iInd");e.d(n,"LocomotionPageModuleNgFactory",function(){return g});var g=o.ob(a,[],function(l){return o.zb([o.Ab(512,o.j,o.Z,[[8,[i.a,h]],[3,o.j],o.v]),o.Ab(4608,b.j,b.i,[o.s,[2,b.p]]),o.Ab(4608,m.c,m.c,[]),o.Ab(4608,r.a,r.a,[o.x,o.g]),o.Ab(4608,r.Cb,r.Cb,[r.a,o.j,o.p]),o.Ab(4608,r.Fb,r.Fb,[r.a,o.j,o.p]),o.Ab(1073742336,b.b,b.b,[]),o.Ab(1073742336,m.b,m.b,[]),o.Ab(1073742336,m.a,m.a,[]),o.Ab(1073742336,r.Ab,r.Ab,[]),o.Ab(1073742336,p.o,p.o,[[2,p.t],[2,p.m]]),o.Ab(1073742336,a,a,[]),o.Ab(1024,p.k,function(){return[[{path:"",component:t}]]},[])])})}}]);